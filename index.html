<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Webcam Pose Estimation</title>
  <style>
    body { margin: 0; overflow: hidden; }
    #video, #canvas {
      position: absolute; top: 0; left: 0;
      width: 100%; height: 100%; object-fit: cover;
    }
    #message {
      position: absolute;
      top: 50%; left: 50%;
      transform: translate(-50%, -50%);
      font-family: sans-serif;
      color: #b00;
      background: rgba(255,255,255,0.9);
      padding: 1em;
      border-radius: 0.5em;
      text-align: center;
      max-width: 90%;
      display: none;
    }
    #retry-button {
      margin-top: 0.5em;
      padding: 0.5em 1em;
      font-size: 1em;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <div id="message"></div>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
  <script>
    (async () => {
      const messageEl = document.getElementById('message');
      function showMessage(text, showRetry = false) {
        messageEl.innerHTML = text;
        if (showRetry) {
          const btn = document.createElement('button');
          btn.id = 'retry-button';
          btn.textContent = 'Retry';
          btn.addEventListener('click', () => location.reload());
          messageEl.appendChild(document.createElement('br'));
          messageEl.appendChild(btn);
        }
        messageEl.style.display = 'block';
      }

      // Detect headless or unsupported preview environments
      if (navigator.webdriver || /HeadlessChrome/.test(navigator.userAgent)) {
        showMessage('ðŸ‘€ Detected a headless or preview environment. Please open this page in a standard browser tab with webcam support.', true);
        return;
      }

      // Secure context check: HTTPS or localhost
      const isLocal = ['localhost', '127.0.0.1', '[::1]'].includes(location.hostname);
      if (location.protocol !== 'https:' && !(location.protocol === 'http:' && isLocal)) {
        showMessage('âš ï¸ Secure context required. Please use HTTPS or serve this page on localhost.', true);
        return;
      }

      async function initCamera() {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          throw new Error('Webcam not supported by your browser.');
        }
        const video = document.getElementById('video');
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio: false });
          video.srcObject = stream;
          await new Promise(res => video.onloadedmetadata = res);
          return video;
        } catch (err) {
          if (['NotAllowedError', 'PermissionDeniedError'].includes(err.name)) {
            throw new Error('Permission denied. Please allow webcam access in your browser settings and reload.');
          }
          throw new Error('Failed to access webcam: ' + err.message);
        }
      }

      async function setupModel() {
        try {
          await tf.setBackend('webgl');
        } catch (e) {
          console.warn('WebGL backend unavailable, switching to CPU.', e);
          await tf.setBackend('cpu');
        }
        await tf.ready();
        const config = { modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING };
        try {
          return await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, config);
        } catch (err) {
          throw new Error('Failed to load pose model: ' + err.message);
        }
      }

      function drawResults(ctx, poses) {
        ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);
        poses.forEach(pose => {
          pose.keypoints.forEach(point => {
            if (point.score > 0.5) {
              ctx.beginPath();
              ctx.arc(point.x, point.y, 5, 0, 2 * Math.PI);
              ctx.fill();
            }
          });
          const pairs = poseDetection.util.getAdjacentPairs(poseDetection.SupportedModels.MoveNet);
          pairs.forEach(([i, j]) => {
            const p1 = pose.keypoints[i], p2 = pose.keypoints[j];
            if (p1.score > 0.5 && p2.score > 0.5) {
              ctx.beginPath();
              ctx.moveTo(p1.x, p1.y);
              ctx.lineTo(p2.x, p2.y);
              ctx.stroke();
            }
          });
        });
      }

      async function renderLoop(video, detector) {
        const canvas = document.getElementById('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const ctx = canvas.getContext('2d');
        async function poseFrame() {
          try {
            const poses = await detector.estimatePoses(video);
            drawResults(ctx, poses);
            requestAnimationFrame(poseFrame);
          } catch (err) {
            console.error('Pose estimation error:', err);
            showMessage('Error during pose estimation: ' + err.message);
          }
        }
        poseFrame();
      }

      try {
        showMessage('ðŸ”„ Initializing camera...');
        const video = await initCamera();
        showMessage('ðŸ”„ Loading model...');
        const detector = await setupModel();
        messageEl.style.display = 'none';
        renderLoop(video, detector);
      } catch (err) {
        console.error(err);
        showMessage(err.message, true);
      }
    })();
  </script>
</body>
</html>
