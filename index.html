<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Webcam Pose Estimation</title>
  <style>
    body { margin: 0; overflow: hidden; }
    #video, #canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
    #message { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); font-family: sans-serif; color: #b00; background: rgba(255,255,255,0.9); padding: 1em; border-radius: 0.5em; text-align: center; max-width: 90%; display: none; }
    #retry-button { margin-top: 0.5em; padding: 0.5em 1em; font-size: 1em; cursor: pointer; }
    #debug { position: absolute; top: 0; left: 0; background: rgba(0,0,0,0.5); color: #0f0; font-family: monospace; padding: 0.5em; white-space: pre; }
  </style>
</head>
<body>
  <div id="message"></div>
  <div id="debug"></div>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
  <script>
    (async () => {
      const messageEl = document.getElementById('message');
      const debugEl = document.getElementById('debug');
      function showMessage(html, showRetry = false) {
        messageEl.innerHTML = html;
        if (showRetry) {
          const btn = document.createElement('button');
          btn.id = 'retry-button';
          btn.textContent = 'Retry';
          btn.addEventListener('click', () => location.reload());
          messageEl.appendChild(document.createElement('br'));
          messageEl.appendChild(btn);
        }
        messageEl.style.display = 'block';
      }

      // Preview/headless detection
      if (navigator.webdriver || /HeadlessChrome/.test(navigator.userAgent)) {
        showMessage('ðŸ‘€ Detected preview or headless environment. Open in a real browser tab.', true);
        return;
      }
      // Secure context
      const isLocal = ['localhost', '127.0.0.1', '[::1]'].includes(location.hostname);
      if (location.protocol !== 'https:' && !(location.protocol === 'http:' && isLocal)) {
        showMessage('âš ï¸ Secure context required (HTTPS or localhost).', true);
        return;
      }

      async function initCamera() {
        const video = document.getElementById('video');
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio: false });
          video.srcObject = stream;
          await new Promise(res => video.onloadedmetadata = res);
          return video;
        } catch (err) {
          console.error('getUserMedia error:', err);
          if (['NotAllowedError','PermissionDeniedError'].includes(err.name)) {
            throw new Error('Camera permission denied. Please allow webcam access and retry.');
          }
          throw new Error('Cannot access webcam: ' + err.message);
        }
      }

      async function setupModel() {
        try { await tf.setBackend('webgl'); } catch {};
        await tf.ready();
        return poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, { modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING });
      }

      function drawResults(ctx, poses) {
        // styling
        ctx.fillStyle = 'lime';
        ctx.strokeStyle = 'lime';
        ctx.lineWidth = 2;
        ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);
        poses.forEach(pose => {
          pose.keypoints.forEach(({ x, y, score }) => {
            if (score > 0.5) {
              ctx.beginPath(); ctx.arc(x, y, 5, 0, 2 * Math.PI); ctx.fill();
            }
          });
          poseDetection.util.getAdjacentPairs(poseDetection.SupportedModels.MoveNet)
            .forEach(([i, j]) => {
              const p1 = pose.keypoints[i], p2 = pose.keypoints[j];
              if (p1.score > 0.5 && p2.score > 0.5) {
                ctx.beginPath(); ctx.moveTo(p1.x, p1.y); ctx.lineTo(p2.x, p2.y); ctx.stroke();
              }
            });
        });
      }

      async function start() {
        let lastTime = performance.now();
        try {
          showMessage('ðŸ”„ Initializing camera...');
          const video = await initCamera();
          showMessage('ðŸ”„ Loading pose model...');
          const detector = await setupModel();
          messageEl.style.display = 'none';

          const canvas = document.getElementById('canvas');
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          const ctx = canvas.getContext('2d');

          (function render() {
            const now = performance.now();
            detector.estimatePoses(video).then(poses => {
              // draw
              drawResults(ctx, poses);
              // update debug: FPS and pose count
              const delta = now - lastTime;
              const fps = 1000 / delta;
              lastTime = now;
              debugEl.textContent = `FPS: ${fps.toFixed(1)}\nPoses: ${poses.length}`;
              requestAnimationFrame(render);
            }).catch(err => {
              console.error('Pose error:', err);
              showMessage('Pose estimation failed: ' + err.message, true);
            });
          })();
        } catch (err) {
          console.error(err);
          showMessage(err.message, true);
        }
      }

      start();
    })();
  </script>
</body>
</html>
